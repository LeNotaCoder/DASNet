# DASNet: A Dual Adaptive Subtle-Feature Network for Enhanced Diabetic Retinopathy Detection in Fundus Images

![DASNet Architecture](path/to/architecture_image.png) <!-- Replace with actual path to your model architecture image -->

## üìÑ Overview

**DASNet** is a novel deep learning architecture designed to improve the early detection of **Diabetic Retinopathy (DR)** using color fundus images (CFIs). The model addresses the challenge of capturing both **subtle lesions** (e.g., microaneurysms) and **prominent features** (e.g., hemorrhages, optic disc changes) by introducing a **dual-branch CNN** that leverages **Adaptive MaxPooling** and standard **MaxPooling** in parallel.

This model was proposed at the **12th Indian Conference on Computer Vision, Graphics and Image Processing (ICVGIP‚Äô25)** and currently under review.

---

## üß† Key Contributions

- **Dual-Branch CNN (DASNet):** Combines adaptive and standard pooling to effectively capture fine-grained and coarse features.
- **Robust Preprocessing Pipeline:** Utilizes HSV conversion and CLAHE on the V-channel to enhance contrast and brightness.
- **Superior Performance:** Outperforms state-of-the-art models (AlexNet, VGG16, ResNet50, InceptionV3) on four datasets.
- **Interpretability:** Visualizes feature maps from each branch to illustrate how different lesions are detected.

---

## üìä Results

| Dataset     | DASNet Accuracy | 
|-------------|------------------|
| BiDR        | 95.92%           | 
| APTOS       | 94.87%           | 
| EDI         | 93.90%           |
| Unified     | 95.63%           |

Refer to Tables 3‚Äì6 in the paper for full metrics (F1, Precision, Recall).

---

## üîç Ablation Study

- Removing **Adaptive Pooling** reduced APTOS accuracy to **92.1%**
- Removing **Max Pooling** reduced APTOS accuracy to **93.6%**
- Removing **Preprocessing** reduced BiDR accuracy to **94.19%**
- Combining both branches and preprocessing led to highest performance

---

## üõ†Ô∏è Model Architecture

DASNet has the following structure:

- Two parallel CNN branches:
  - Branch 1: Conv layers + **Adaptive MaxPooling**
  - Branch 2: Conv layers + **MaxPooling**
- Feature map concatenation
- Deep convolutional stack + FC layers
- Dropout regularization
- Final binary classification (Healthy vs DR)

---

## üñºÔ∏è Preprocessing Pipeline

1. Resize images to `224√ó224`
2. Convert BGR ‚Üí HSV
3. Apply **CLAHE** on Value (V) channel
4. Reconvert to RGB

This enhances subtle lesion visibility across lighting conditions.

---

## üìÅ Datasets Used

1. **BiDR**
2. **APTOS 2019**
3. **Eye Disease Image (EDI)**
4. **Unified Dataset** (Eyepacs, Aptos, Messidor)

All datasets were normalized into binary labels: `0 = Healthy`, `1 = DR`.

---

## üß™ Training Setup

- Optimizer: `Adam`
- Loss: `Binary Cross-Entropy`
- Epochs: `25`
- Batch Size: `32`
- Hardware: `NVIDIA A100 (80GB)`
- Train/Test Split: `80/20`

---

## üìà Visualization

Feature maps from:
- **Adaptive Pooling** branch: fine textures and microaneurysms
- **MaxPooling** branch: vessel structures, optic disc, hemorrhages

---
